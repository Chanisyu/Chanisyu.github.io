<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-07-04T03:35:48+00:00</updated><id>http://localhost:4000/</id><title type="html">图</title><subtitle>Record ideas and knowledge</subtitle><author><name>lihuimintu</name></author><entry><title type="html">HBase Meta 表</title><link href="http://localhost:4000/2019/06/30/HBase-Meta/" rel="alternate" type="text/html" title="HBase Meta 表" /><published>2019-06-30T00:00:00+00:00</published><updated>2019-06-30T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/30/HBase-Meta</id><content type="html" xml:base="http://localhost:4000/2019/06/30/HBase-Meta/">&lt;p&gt;HBase Meta 表&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;目录表 hbase:meta 作为HBase 表存在，并从 HBase shell 的list命令中过滤掉（命名空间”hbase”下的表都会过滤掉），但实际上是一个表，就像任何其他表一样。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-07-01-1.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;meta-表&quot;&gt;meta 表&lt;/h4&gt;

&lt;p&gt;hbase:meta 表属于系统表&lt;/p&gt;

&lt;p&gt;META表是一个保存的了系统中所有 Region 列表的 HBase 表&lt;/p&gt;

&lt;p&gt;它保存在一个 RS 上面，那如何去知道它在哪个 RS 上呢？ 这就要利用 zk 了&lt;/p&gt;

&lt;p&gt;meta 表的地址信息保存在 zk 的 /hbase 路径下的 meta-region-server 节点上&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-07-01-2.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;表结构&quot;&gt;表结构&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-07-01-3.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Key: Region key of the format ([table表名],[region start key起始键],[region id])&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;region id 由该 region 生成的时间戳（精确到毫秒）与 region encoded 组成&lt;/code&gt;&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;region encoded 由 region 所在的 表名, StartKey, 时间戳这三者的MD5值产生，HBase 在 HDFS 上存储 region 的路径就是 region encoded。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;key 被用来表示 region name&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-07-01-4.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;values:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;info:regioninfo, RegionInfo 的 encodeValue值&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;info:seqnumDuringOpen, 序列号&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;info:server, Region 所在的 RS&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;info:serverstartcode, RS 启动的 timestamp&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-07-01-5.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于 HRegionInfo 的注释&lt;/p&gt;

&lt;p&gt;空键用于表示表开始和表结束。具有空开始键的区域是表中的第一个区域。如果某个区域同时具有空开始和空结束键，则它是表中唯一的区域&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://yq.aliyun.com/articles/586755?utm_content=m_48695&quot;&gt;HBase运维基础——元数据逆向修复原理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">HBase Meta 表</summary></entry><entry><title type="html">HBase Region 过多导致集群问题事件</title><link href="http://localhost:4000/2019/06/27/HBase-IO-Case/" rel="alternate" type="text/html" title="HBase Region 过多导致集群问题事件" /><published>2019-06-27T00:00:00+00:00</published><updated>2019-06-27T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/27/HBase-IO-Case</id><content type="html" xml:base="http://localhost:4000/2019/06/27/HBase-IO-Case/">&lt;p&gt;HBase Region 过多导致的集群性能不佳&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;有 10 个节点的HBase集群。每天早上 10 点所有 RS warn 告警。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-1.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;持续过程 30 分钟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-2.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GC 时间过长，还触发了 RS 宕机。&lt;/p&gt;

&lt;h4 id=&quot;问题分析&quot;&gt;问题分析&lt;/h4&gt;

&lt;p&gt;优先看 GC 告警的机器。查看 CM 监控发现该机器的 CPU，磁盘吞吐量在 10:00 - 10:30 这一段时间都是飙高的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-3.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我接着查看发现所有的 RS 都是 10:00 - 10:30 这一段时间都是飙高的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-4.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;肯定是什么触发的。先看读写读写量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-5.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;读写量也不大，说明不是由大批量请求造成的。&lt;/p&gt;

&lt;p&gt;监控看不出问题，那就转战看日志。&lt;/p&gt;

&lt;p&gt;发现有很多类似如下的输出:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;... because info has and old edit so flush to free WALs after random delay ...&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-6.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是很明显的写入量很小，因为周期性 flush 线程触发的行为，比如某 store 很久没更新了而最新的 edit 距今超过阈值（默认 1小时），
那么就会 delay 一个 random 时间去执行刷新。参阅&lt;a href=&quot;https://lihuimintu.github.io/2019/06/25/HBase-Flush/&quot;&gt;HBase Flush 时机&lt;/a&gt;
第5点定期刷新&lt;/p&gt;

&lt;p&gt;通过如下关键字去看历次触发的 flush 产生的文件大小&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;grep 'org.apache.hadoop.hbase.regionserver.HStore: Added hdfs' /var/log/hbase/hbase-cmf-hbase-REGIONSERVER-${FQDN_HOSTNAME}.log.out | awk '{print $1&quot; &quot;$2&quot; &quot;$(NF-1)$NF}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-7.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;发现几乎每次刷出来的都是小文件，不到 100KB。&lt;/p&gt;

&lt;p&gt;为什么这么多小文件呢？小文件过多会触发 compaction 机制。&lt;/p&gt;

&lt;p&gt;刚好同事已经排查出小文件过多原因。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-8.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;HBase 集群的 Region 个数达到了 2w 个。因为该 HBase 集群上有 Kylin 服务。Kylin 生成了大量的临时表。
而清理临时表的定时脚本因配置不当没有启动起来。导致该 HBase 集群 Region 个数越来越多。Region 越多，MemStore 刷新越小，
所以产生了小 HFile 文件。&lt;/p&gt;

&lt;p&gt;compaction 机制检查到 Store 中 HFile 个数达到 3 个时就会执行 Compaction&lt;/p&gt;

&lt;p&gt;同事手动运行脚本之后已经将 Region 个数降到 2k 左右了，平摊到 10 个RS就是 200+ 个。符合合理范围。&lt;a href=&quot;https://mp.weixin.qq.com/s/0tGNpmBRHbI673TwxIC2NA&quot;&gt;HBase最佳实践之Region数量&amp;amp;大小&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;原因找到了，那我就找找 compaction 发生的痕迹。验证是由 compaction 触发导致服务器压力大。&lt;/p&gt;

&lt;p&gt;根据监控上的时间点。看到 CPU 在 10:06 分达到峰值。在日志里查询 10:06 左右发生了什么事。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-9.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;功夫不负有心人，看到关键&lt;code class=&quot;highlighter-rouge&quot;&gt; CompactionChecker missed its start time&lt;/code&gt;(图中绿色框)。&lt;/p&gt;

&lt;p&gt;翻译过来就是 CompactionChecker 线程丢失了开始时间。为什么丢失开始时间是因为发生了 GC 造成了 STW(图中蓝色框)，线程被挂起了。这不是重点，接着往下看。&lt;/p&gt;

&lt;p&gt;CompactionChecker 线程是干什么的？&lt;/p&gt;

&lt;p&gt;CompactionChecker 是RS上的工作线程(Chore)。后台线程 CompactionChecker 定期触发检查是否需要执行 compaction，设置执行周期是通过 threadWakeFrequency 指定。
大小通过 hbase.server.thread.wakefrequency 配置(默认10000)，然后乘以默认倍数 hbase.server.compactchecker.interval.multiplier (1000), 毫秒时间转换为秒。因此，在不做参数修改的情况下，CompactionChecker大概是2hrs 46mins 40sec 执行一次。&lt;/p&gt;

&lt;p&gt;接着日志我往前翻上一次 CompactionChecker 时间。得到以下信息。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-06-27 07:12:02,093 INFO org.apache.hadoop.hbase.ScheduledChore: Chore: CompactionChecker missed its start time
...skipping...
2019-06-27 10:06:20,649 INFO org.apache.hadoop.hbase.ScheduledChore: Chore: CompactionChecker missed its start time
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以计算可以知道两个时间相差 2时 54分 18秒。符合 CompactionChecker 间隔时间。查看 RS 6点到 8点 CPU 监控。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-27-10.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出 7:12 之后 CPU 峰值降下来了。&lt;/p&gt;

&lt;p&gt;正如猜想一样。CompactionChecker 是关键。&lt;/p&gt;

&lt;h4 id=&quot;思路归纳&quot;&gt;思路归纳&lt;/h4&gt;

&lt;p&gt;Region 过多会影响 HBase 状态。Region 之间共享 RS 的 MemStore 内存区域，因此 Region 过多，MemStore 刷新越小。&lt;/p&gt;

&lt;p&gt;当 memstore 满后，就不得不刷新到文件系统，会创建一个数据存储在 HDFS 上的 HFile。&lt;/p&gt;

&lt;p&gt;这也意味着 Region 越多，产生的 HFile 越小。&lt;/p&gt;

&lt;p&gt;这个也迫使 HBase 执行大量的合并操作才能保持 HFile 的数量低至合理数目。&lt;/p&gt;

&lt;p&gt;这些合并操作对集群产生了过多扰动，进而影响集群性能。&lt;/p&gt;

&lt;p&gt;到了这里基本可以结案了。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/a0056a35f982&quot;&gt;HBase 线上问题排查 - 为什么读写这么少还会触发巨量 IO ？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/qq_23160237/article/details/89309402&quot;&gt;一次region过多导致HBase服务宕机事件&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/0tGNpmBRHbI673TwxIC2NA&quot;&gt;HBase最佳实践之Region数量&amp;amp;大小&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">HBase Region 过多导致的集群性能不佳</summary></entry><entry><title type="html">Linux 命令记录</title><link href="http://localhost:4000/2019/06/26/Linux-Command/" rel="alternate" type="text/html" title="Linux 命令记录" /><published>2019-06-26T00:00:00+00:00</published><updated>2019-06-26T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/26/Linux-Command</id><content type="html" xml:base="http://localhost:4000/2019/06/26/Linux-Command/">&lt;p&gt;运维过程中所接触到的 Linux 命令&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;有人分享技术面试时说到面试官让其将用到的哪些linux命令，全写下来。&lt;/p&gt;

&lt;p&gt;因此我也想总结下自己运维过程中所接触到的 Linux 命令&lt;/p&gt;

&lt;p&gt;不会记录的很详细。想到记录什么就记录什么。&lt;/p&gt;

&lt;h4 id=&quot;crontab&quot;&gt;crontab&lt;/h4&gt;

&lt;p&gt;查看某个用户的 cron 任务&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;crontab -u username -l
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看所有用户的 cron 任务&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 以root用户执行
cat /etc/passwd | cut -f 1 -d : |xargs -I {} crontab -l -u {}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;bc&quot;&gt;bc&lt;/h4&gt;

&lt;p&gt;bc命令是一种支持任意精度的交互执行的计算器语言。是Linux简单的计算器,能进行进制转换与计算。&lt;/p&gt;

&lt;p&gt;执行浮点运算&lt;/p&gt;

&lt;p&gt;参数 scale=3 是将bc输出结果的小数位设置为3位&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;scale=3;10/3&quot; | bc
3.333
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;进制转换&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;obase=2;$255&quot; | bc
11111111
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>lihuimintu</name></author><summary type="html">运维过程中所接触到的 Linux 命令</summary></entry><entry><title type="html">HBase Flush 时机</title><link href="http://localhost:4000/2019/06/25/HBase-Flush/" rel="alternate" type="text/html" title="HBase Flush 时机" /><published>2019-06-25T00:00:00+00:00</published><updated>2019-06-25T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/25/HBase-Flush</id><content type="html" xml:base="http://localhost:4000/2019/06/25/HBase-Flush/">&lt;p&gt;HBase MemStore 的刷写时机&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;flush-时机&quot;&gt;Flush 时机&lt;/h4&gt;

&lt;p&gt;HBase 会在如下几种情况下触发 flush 操作，需要注意的是 MemStore 的最小 flush 单元是 HRegion 
而不是单个 MemStore。可想而知，如果一个 HRegion 中 Memstore 过多，每次 flush 的开销必然会很大，
因此建议在进行表设计的时候尽量减少 ColumnFamily 的个数。&lt;/p&gt;

&lt;p&gt;根据 HBase 官方文档总结的刷写时机有6种:&lt;/p&gt;
&lt;h5 id=&quot;1-memstore-级别限&quot;&gt;1. MemStore 级别限&lt;/h5&gt;

&lt;p&gt;当 Region 中任意一个 MemStore 的大小达到了上限(hbase.hregion.memstore.flush.size，默认128MB)，会触发 MemStore 刷新。&lt;/p&gt;

&lt;h5 id=&quot;2-region-级别限制&quot;&gt;2. Region 级别限制&lt;/h5&gt;

&lt;p&gt;当 Region 中所有 MemStore 的大小总和达到了上限(hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size，默认 4 * 128M = 512M)，会触发 MemStore 刷新。&lt;/p&gt;

&lt;h5 id=&quot;3-region-server-级别限制&quot;&gt;3. Region Server 级别限制&lt;/h5&gt;

&lt;p&gt;当 Region Server 内部所有 MemStore 总和大小达到分配给 MemStore 最大内存(hbase_heapsize * hbase.regionserver.global.memstore.size, 默认0.4，也就是堆内存的40%)，会触发刷写阻塞。
低于分配给 MemStore 最大内存，高于 Memstore 刷新的低水位线(hbase.regionserver.global.memstore.size.lower.limit, 默认值 0.95), 会触发刷写。&lt;/p&gt;

&lt;p&gt;总体来说，如果全局 MemStore 的总和达到了分配给 MemStore 最大内存的95%，就会导致全局刷写，默认有40%的内存会分给 MemStore。而当超过了 MemStore 的最大内存，也就是堆内存的40%就会触发刷写阻塞。&lt;/p&gt;

&lt;p&gt;如果有16G堆内存，默认情况下:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#达到该值会触发刷写
16*0.4*0.95=0.608
#达到该值会触发刷写阻塞
16*0.4=6.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;相信好多人会在网上看到 hbase.regionserver.global.memstore.upperLimit、hbase.regionserver.global.memstore.lowerLimit 这两个参数。&lt;/p&gt;

&lt;p&gt;这两个参数已经发生了改变了。对应的新参数如下:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;新参数&lt;/th&gt;
      &lt;th&gt;老参数&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;hbase.regionserver.global.memstore.size&lt;/td&gt;
      &lt;td&gt;hbase.regionserver.global.memstore.upperLimit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;hbase.regionserver.global.memstore.size.lower.limit&lt;/td&gt;
      &lt;td&gt;hbase.regionserver.global.memstore.lowerLimit&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;的确，当时我也看了老版本的 Region Server 级别限制:
&lt;code class=&quot;highlighter-rouge&quot;&gt;当一个Region Server中所有Memstore的大小总和达到了上限（hbase.regionserver.global.memstore.upperLimit ＊ hbase_heapsize，默认 40%的JVM内存使用量），会触发部分Memstore刷新。Flush顺序是按照Memstore由大到小执行，先Flush Memstore最大的Region，再执行次大的，直至总体Memstore内存使用量低于阈值（hbase.regionserver.global.memstore.lowerLimit ＊ hbase_heapsize，默认 38%的JVM内存使用量）。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;按照老版本来看，我发现新搭建的集群配置怎么不对，lowerLimit 怎么比 upperLimit 还高。一度让我弄混。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-25-1.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;直到我弄清楚 hbase.regionserver.global.memstore.size.lower.limit 是分配给 MemStore 最大内存的刷新的低水位线才明白。&lt;/p&gt;

&lt;p&gt;大家可以参阅官方文档对两个新参数的解释。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-25-2.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;4-hlog-数量限制&quot;&gt;4. HLog 数量限制&lt;/h5&gt;

&lt;p&gt;当一个 Region Server 中 HLog 数量达到上限(可通过参数 hbase.regionserver.maxlogs 配置)时，系统会选取最早的一个 HLog 对应的一个或多个 Region 进行 flush&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-25-3.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;5-定期刷新&quot;&gt;5. 定期刷新&lt;/h5&gt;

&lt;p&gt;HBase 定期刷新 MemStore (hbase.regionserver.optionalcacheflushinterval), 默认周期为1小时，确保 MemStore 不会长时间没有持久化。为避免所有的 MemStore 在同一时间都进行 flush 导致的问题，定期的 flush 操作有 20000 左右的随机延时。&lt;/p&gt;

&lt;p&gt;hbase.regionserver.optionalcacheflushinterval 参数设置为 0 可关闭。CDH 管理页面上没有直接设置&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-25-4.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;6-手动执行&quot;&gt;6. 手动执行&lt;/h5&gt;

&lt;p&gt;可以通过 shell 命令 flush ‘tableName’ 或者 flush ‘regionName’ 分别对一个表或者一个 Region 进行 flush。&lt;/p&gt;

&lt;h5 id=&quot;7-其他&quot;&gt;7. 其他&lt;/h5&gt;

&lt;p&gt;执行 Compact 和 Split 之前，会进行一次 flush&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.tencent.com/developer/article/1005744&quot;&gt;Hbase memstore 的刷写时机&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hbase.apache.org/1.2/book.html&quot;&gt;HBase1.2官方文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">HBase MemStore 的刷写时机</summary></entry><entry><title type="html">SSH 使用私钥登陆</title><link href="http://localhost:4000/2019/06/24/SSH-ssh_rsa/" rel="alternate" type="text/html" title="SSH 使用私钥登陆" /><published>2019-06-24T00:00:00+00:00</published><updated>2019-06-24T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/24/SSH-ssh_rsa</id><content type="html" xml:base="http://localhost:4000/2019/06/24/SSH-ssh_rsa/">&lt;p&gt;SSH 使用私钥登陆&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;今天大数据开发找到我，让我帮他到业务运维机器上 scp 一个文件到大数据的接口机上。&lt;/p&gt;

&lt;p&gt;业务运维发了一个 key 文件给我，让我通过 key 文件上去拿。&lt;/p&gt;

&lt;p&gt;我登陆服务器都是用密码登陆的，这种用 key 的方式不会。&lt;/p&gt;

&lt;p&gt;赶紧某歌学习下，并记录下来&lt;/p&gt;

&lt;h4 id=&quot;私钥公钥&quot;&gt;私钥、公钥&lt;/h4&gt;

&lt;p&gt;在当前用户家目录下的 .ssh 可以看到如下文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@zhazhahui .ssh]# ls
authorized_keys  id_rsa  id_rsa.pub  known_hosts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;id_rsa 为私钥、id_rsa.pub 为公钥&lt;/p&gt;

&lt;p&gt;对比同事发的内容，知道发给我的是私钥。&lt;/p&gt;

&lt;p&gt;那就是他把私钥对应的公钥复制到了 authorized_keys 文件内了&lt;/p&gt;

&lt;p&gt;我直接拿他给的私钥登陆即可&lt;/p&gt;

&lt;h4 id=&quot;步骤&quot;&gt;步骤&lt;/h4&gt;

&lt;p&gt;1 导入私钥，将私钥文件放到当前登陆用户目录下的 .ssh 目录下。&lt;/p&gt;

&lt;p&gt;将发给我的私钥写入 ssh_rsa 文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim ssh_rsa
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;指定私钥登陆&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh -i .ssh/ssh_rsa  root@target.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果出现了下面这种情况&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-1.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是因为私钥文件权限太高了，比较不安全，所以被阻止，需要将ssh_rsa的权限设置低一些比如 0400&lt;/p&gt;

&lt;p&gt;chmod 0400 .ssh/ssh_rsa&lt;/p&gt;

&lt;p&gt;这样就可以登陆成功了&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/demonxian3/p/8331545.html&quot;&gt;SSH私用私钥登陆&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/hellotracy/articles/5179985.html&quot;&gt;ssh public key private key 免密码&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.runoob.com/w3cnote/set-ssh-login-key.html&quot;&gt;设置 SSH 通过密钥登录&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">SSH 使用私钥登陆</summary></entry><entry><title type="html">记一次 RegionServer 宕机排查过程</title><link href="http://localhost:4000/2019/06/24/HBase-RS-shutdown/" rel="alternate" type="text/html" title="记一次 RegionServer 宕机排查过程" /><published>2019-06-24T00:00:00+00:00</published><updated>2019-06-24T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/24/HBase-RS-shutdown</id><content type="html" xml:base="http://localhost:4000/2019/06/24/HBase-RS-shutdown/">&lt;p&gt;记一次 RegionServer 宕机排查过程&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;头大，今天 HBase 集群写入压力过大，一直报压缩队列的警告。&lt;/p&gt;

&lt;p&gt;接着突然间来了一个 RS 宕机的告警。凉凉。赶紧查看，同事已经先行一步将其启动起来了。&lt;/p&gt;

&lt;p&gt;查看 CM 读写请求曲线，发现并不是很大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-4.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;查看日志&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-5.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到有一段时间日志没有更新，往后看到下方日志&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-06-24 16:47:28,787 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 258006ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2019-06-24 16:47:28,788 WARN org.apache.hadoop.hbase.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 257656ms
No GCs detected
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看出，HBase 发生了 Stop The World(停顿类型STW) ，导致整个进程所有线程被挂起了 257s。将近 4 分钟多。&lt;/p&gt;

&lt;p&gt;查看对应的 GC 日志&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-6.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;发现 CMS-concurrent-sweep 持续了 433.98 secs 。 orz&lt;/p&gt;

&lt;h4 id=&quot;排查&quot;&gt;排查&lt;/h4&gt;

&lt;p&gt;接着来看看 RS 宕机的直接原因&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-7.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-8.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;log 回滚报错，报错原因是  Parent directory doesn’t exist: /hbaseploan/WALs/yz-jdb-106-37-25,60020,1561114085906。
因为文件不存在了， log writer 获取失败。&lt;/p&gt;

&lt;p&gt;为什么不存在呢？ 接着看&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-9.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看样子估计是 WAL 日志所在的块丢失了。&lt;/p&gt;

&lt;p&gt;接着看为什么会丢失&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-10.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从日志内容来看应该是 HBase 调用DFSClient向 DN 写入 block 数据”BP-326682921-100.106.41.1-1466507608648:blk_5358896052_4480910033″，但是 DN 返回失败， recover 过程也是 ERROR的。具体失败原因需要查看 DN 节点日志，如下所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-11.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;很显然，从日志可以看出，DN 一直在等待来自客户端的 read 请求，但是直至 SocketTimeout，请求都没有过来，此时 DN 会将该连接断开。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-12.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;估计因为断开连接，所以这个 block 出现了写故障，恢复也失败了。&lt;/p&gt;

&lt;p&gt;然后该块丢失导致 log 操作文件时失败。&lt;/p&gt;

&lt;p&gt;因此 RS 才宕机的。&lt;/p&gt;

&lt;p&gt;罪魁祸首就是 GC 导致的 Stop The World&lt;/p&gt;

&lt;p&gt;但是什么导致的 GC。由于监控简陋，未清楚原因。打算研究部署一套 Ganglia 来实现监控。&lt;/p&gt;

&lt;p&gt;为什么 block 恢复也失败。我也没找到原因。涉及到 HDFS pipeline 写。有机会补补这方面知识。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://hbasefly.com/2016/04/15/hbase-regionserver-crash/&quot;&gt;HBase问题诊断 – RegionServer宕机&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.yoodb.com/sugarliny/article/detail/1306&quot;&gt;Hbase Region Server异常分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">记一次 RegionServer 宕机排查过程</summary></entry><entry><title type="html">GC 日志详解</title><link href="http://localhost:4000/2019/06/24/GC-Log-Detailed/" rel="alternate" type="text/html" title="GC 日志详解" /><published>2019-06-24T00:00:00+00:00</published><updated>2019-06-24T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/24/GC-Log-Detailed</id><content type="html" xml:base="http://localhost:4000/2019/06/24/GC-Log-Detailed/">&lt;p&gt;Java GC 日志详解（一图读懂）&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;Java GC日志可以通过设置 -XX:+PrintGCDetails 标志创建更详细的GC日志。具体的可以参考&lt;a href=&quot;https://lihuimintu.github.io/2019/02/19/gcLog/&quot;&gt;JVM 配置GC日志&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;图解&quot;&gt;图解&lt;/h4&gt;

&lt;p&gt;以 ParallelGC 为例&lt;/p&gt;

&lt;p&gt;YoungGC 日志解释如下（图片源地址：&lt;a href=&quot;http://ww4.sinaimg.cn/large/6c8effc1tw1dmbux7knpoj.jpg&quot;&gt;这里&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-2.png&quot; alt=&quot;YoungGC&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FullGC（图片源地址：&lt;a href=&quot;http://ww1.sinaimg.cn/large/6c8effc1tw1dmc55axrbsj.jpg&quot;&gt;这里&lt;/a&gt;）:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-24-3.png&quot; alt=&quot;FullGC&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图来源于网络，侵删。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/ade514d7c56b&quot;&gt;Java GC 日志详解（一图读懂）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">Java GC 日志详解（一图读懂）</summary></entry><entry><title type="html">HBase LinkFile</title><link href="http://localhost:4000/2019/06/20/HBase-LinkFile/" rel="alternate" type="text/html" title="HBase LinkFile" /><published>2019-06-20T00:00:00+00:00</published><updated>2019-06-20T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/20/HBase-LinkFile</id><content type="html" xml:base="http://localhost:4000/2019/06/20/HBase-LinkFile/">&lt;p&gt;clone_snapshot 的关键 linkfile&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;今天 HBase 维护过程中打开了 /hbase/archive 路径，发现该路径下面存在文件。&lt;/p&gt;

&lt;p&gt;/hbase/archive 为归档路径，HBase 在做 Split , Compact，Drop 操作完成之后，
会将 HFile 移到 archive 目录中, 然后将之前的 hfile 删除掉, 该目录由 HMaster 上的一个定时任务定期5分钟去清理.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-20-1.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;都18年6月份的数据了，怎么还没删掉。这不科学。这开启了我的探索之旅&lt;/p&gt;

&lt;h4 id=&quot;分析&quot;&gt;分析&lt;/h4&gt;

&lt;p&gt;某度搜索到对表做了 snapshot 的话，archive 不会被清理。&lt;/p&gt;

&lt;p&gt;然后 hbase shell 中输入 list_snapshots 的确看到该表存在快照。(忘记留图了)&lt;/p&gt;

&lt;p&gt;确认该快照已经不需要的情况下，我对其进行了删除。&lt;/p&gt;

&lt;p&gt;10 分钟后观察发现还未删除。。。。这就有点尴尬了。&lt;/p&gt;

&lt;p&gt;之前也遇到过一次 archive 目录下表的 HFile 文件是用 bulkload 方式加载的，HFile 文件权限不够，HBase 无法删除，
所以这次我也猜测是不是这个原因。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-20-2.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ls 查看后发现都是 hbase 的权限。这可咋办啊。这时我留意到有个 .links-ba0feda3ca8d499a9eb375503ad943c2 的目录&lt;/p&gt;

&lt;p&gt;这个目录干嘛的。我对此产生疑惑&lt;/p&gt;

&lt;h4 id=&quot;linkfile&quot;&gt;LinkFile&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-20-3.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;进去看了之后，发现是个 back-reference 文件，这时就明白了，估计是 Snapshot 的恢复表一个指引。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-20-4.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;正如猜想一样。就是恢复表的一个指引, 即 clone 生成的 LinkFile。&lt;/p&gt;

&lt;p&gt;HBase 就是利用在删除 archive 中原始表文件的时候知道这些文件还被一些恢复表的 LinkFile 引用着&lt;/p&gt;

&lt;p&gt;LinkFile 和 back-reference 文件格式如下所说。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;（1）原始文件: /hbase/data/table-x/region-x/cf/file-x
（2）clone 生成的 LinkFile: /hbase/data/table-cloned/region-y/cf/{table-x}={region-x}-{file-x}，因此可以很容易根据LinkFile定位到原始文件
（3）back-reference 文件: /hbase/.archive/data/table-x/region-x/cf/.links-file-x/{region-y}.{table-cloned}，可以看到，back-reference文件路径中包含所有原始文件和LinkFile的信息，因此可以有效的根据原始文件/table-x/region-x/cf/file-x定位到LinkFile：/table-cloned/region-y/cf/{table-x}-{region-x}-{file-x}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;举个例子。假设&lt;/p&gt;

&lt;p&gt;LinkFile 文件名为 music=5e54d8620eae123761e5290e618d556b-f928e045bb1e41ecbef6fc28ec2d5712。&lt;/p&gt;

&lt;p&gt;根据定义可以知道 music 为原始文件的表名，5e54d8620eae123761e5290e618d556b 为引用文件所在的 region，f928e045bb1e41ecbef6fc28ec2d5712 为引用的 HFile 文件&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-20-5.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以依据规则可以直接根据LinkFile的文件名定位到引用文件所在位置&lt;/p&gt;

&lt;p&gt;***/music/5e54d8620eae123761e5290e618d556b/cf/f928e045bb1e41ecbef6fc28ec2d5712&lt;/p&gt;

&lt;p&gt;如果在 music 表的 HFile 被放置到 archive 目录下，则会生成一个 back-reference 文件&lt;/p&gt;

&lt;p&gt;根据这个 back-reference 文件 HBase 才知道该 HFile 该不该清理。&lt;/p&gt;

&lt;p&gt;HFileLinkCleaner 负责清理这类 HFile。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-20-6.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过注释可以了解到，如果对 archive 中的文件的引用不存在了，则可以删除。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * HFileLink cleaner that determines if a hfile should be deleted.
 * HFiles can be deleted only if there're no links to them.
 *
 * When a HFileLink is created a back reference file is created in:
 *      /hbase/archive/table/region/cf/.links-hfile/ref-region.ref-table
 * To check if the hfile can be deleted the back references folder must be empty.
 */
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;清理&quot;&gt;清理&lt;/h4&gt;

&lt;p&gt;如果想尽快清理掉，有两种方法。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对恢复表做个 major_compact 即可把指引的 HFile 写入到恢复表上。指引文件会消失。&lt;/li&gt;
  &lt;li&gt;删除恢复表&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;

&lt;p&gt;其实之前就学过 snapshot 的知识，只是太久没回顾了，又有点忘记了。导致这次花了点时间。&lt;/p&gt;

&lt;p&gt;如果有没讲清的地方，可以留言，也可以自行阅读参考链接。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://hbasefly.com/2017/09/17/hbase-snapshot/&quot;&gt;HBase原理 – 分布式系统中snapshot是怎么玩的？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/f82aafd7b381&quot;&gt;HMaster 功能之定期清理archive&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/qq_31598113/article/details/79934919&quot;&gt;Hbase在hdfs上的archive目录占用空间过大&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">clone_snapshot 的关键 linkfile</summary></entry><entry><title type="html">HBase 目录结构</title><link href="http://localhost:4000/2019/06/19/HBase-File-ZK-Structure/" rel="alternate" type="text/html" title="HBase 目录结构" /><published>2019-06-19T00:00:00+00:00</published><updated>2019-06-19T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/19/HBase-File-ZK-Structure</id><content type="html" xml:base="http://localhost:4000/2019/06/19/HBase-File-ZK-Structure/">&lt;p&gt;HBase 在 HDFS 存储目录结构、在 Zookeeper 的目录结构&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;HBase 在 HDFS 存储目录结构、在 Zookeeper 的目录结构&lt;/p&gt;

&lt;h4 id=&quot;在-hdfs-路径&quot;&gt;在 HDFS 路径&lt;/h4&gt;

&lt;p&gt;HBase 在 HDFS 默认根目录: &lt;code class=&quot;highlighter-rouge&quot;&gt;/hbase&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;配置项 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;name&amp;gt; hbase.rootdir &amp;lt;/name&amp;gt; &lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@massive-dataset-new-005 ~]# hadoop fs -ls /hbase
Found 10 items
drwxr-xr-x   - hbase hbase          0 2019-02-22 11:20 /hbase/.hbase-snapshot   # 存储的是 Snapshot 的相关信息
drwxr-xr-x   - hbase hbase          0 2019-06-10 20:57 /hbase/.tmp              # 临时目录。当对表进行操作的时候，首先会将表移动到该目录下，然后再进行操作。
drwxr-xr-x   - hbase hbase          0 2019-06-19 20:17 /hbase/MasterProcWALs    # 一个HMaster主节点状态日志文件。
drwxr-xr-x   - hbase hbase          0 2019-06-19 19:12 /hbase/WALs              # 预写日志，和 Hadoop 中的 edits 文件类似，作用是容灾
drwxr-xr-x   - hbase hbase          0 2019-06-19 19:25 /hbase/archive           # HBase 在做 Split , Compact，Drop 操作完成之后，会将 HFile 移到 archive 目录中,然后将之前的 hfile 删除掉,该目录由 HMaster 上的一个定时任务定期去清理. 
drwxr-xr-x   - hbase hbase          0 2019-01-30 16:55 /hbase/corrupt           # 存储 HBase 做损坏的日志文件，一般都是为空的
drwxr-xr-x   - hbase hbase          0 2019-06-11 11:44 /hbase/data              # HBase 的表数据目录，0.98版本里支持 namespace 的概念模型，系统会预置两个 namespace 即: hbase 和 default
-rw-r--r--   3 hbase hbase         42 2018-12-25 15:31 /hbase/hbase.id          # 它是一个文件，存储集群唯一的 cluster id 号，是一个 uuid
-rw-r--r--   3 hbase hbase          7 2018-12-25 15:31 /hbase/hbase.version     # 同样也是一个文件，存储集群的版本号，貌似是加密的，看不到，只能通过web-ui 才能正确显示出来  
drwxr-xr-x   - hbase hbase          0 2019-06-19 19:54 /hbase/oldWALs           # 预写日志归档目录，参数 hbase.master.logcleaner.ttl 控制此文件会定时被清除，默认是 10 分钟
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;MasterProcWALs 解释下。由于目前几乎所有的集群操作都是通过 procedure 进行的。 &lt;br /&gt;
procedure 执行的每一步都会以log的形式持久化在 HBase 的 MasterProcWals 目录下，这样 master 在重启时也能通过日志来恢复之前的状态并且继续执行。&lt;br /&gt;
完成的操作日志一段时间后会被删除&lt;/p&gt;

&lt;p&gt;/hbase/archive 目录下的数据会过期清理，但是 Snapshot 对应的数据不会被清理，除非删除对应 Snapshot。
只要原来的文件有被删除的情况，如 Compaction，Split, Drop 操作，那么快照所引用的hfile文件都会归档到archive的对应表目录中。&lt;/p&gt;

&lt;p&gt;HBase 的表数据目录首先是 namespace。hbase、default 是 HBase 自带的 namespace&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@massive-dataset-new-005 ~]# hadoop fs -ls /hbase/data
Found 4 items
drwxr-xr-x   - hbase hbase          0 2019-06-19 19:12 /hbase/data/default
drwxr-xr-x   - hbase hbase          0 2018-12-25 15:31 /hbase/data/hbase
drwxr-xr-x   - hbase hbase          0 2019-03-06 10:38 /hbase/data/mytest
drwxr-xr-x   - hbase hbase          0 2019-01-03 14:41 /hbase/data/nametest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;hbase 这个 namespace 下面存储了 HBase 的 namespace、meta 和 acl 三个表。 &lt;br /&gt;
如果没有开启 HBase 权限的话不会有 acl 这个表。 启用 HBase 授权。设置 hbase.security.authorization = true&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@aaadddccc ~]# hadoop fs -ls /hbase/data/hbase
Found 3 items
drwxr-xr-x   - hbase supergroup          0 2018-04-16 21:12 /hbase/data/hbase/acl
drwxr-xr-x   - hbase supergroup          0 2016-06-30 19:03 /hbase/data/hbase/meta
drwxr-xr-x   - hbase supergroup          0 2016-06-30 19:04 /hbase/data/hbase/namespace
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;每张表都维护 tabledesc 和 regioninfo&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@massive-dataset-new-005 ~]# hadoop fs -ls /hbase/data/default/tu
Found 3 items
drwxr-xr-x   - hbase hbase          0 2019-06-01 15:59 /hbase/data/default/tu/.tabledesc    # 表的元数据目录
drwxr-xr-x   - hbase hbase          0 2019-06-01 15:59 /hbase/data/default/tu/.tmp          # 中间临时数据，当 .tableinfo 被更新时该目录就会被用到
drwxr-xr-x   - hbase hbase          0 2019-06-08 21:06 /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd  # encoded_regionname 即 region 编码名

[root@massive-dataset-new-005 ~]# hadoop fs -ls /hbase/data/default/tu/.tabledesc
Found 1 items
-rw-r--r--   3 hbase hbase        285 2019-06-01 15:59 /hbase/data/default/tu/.tabledesc/.tableinfo.0000000001 # 表元数据信息具体文件

[root@massive-dataset-new-005 ~]# hadoop fs -ls /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd
Found 4 items
-rw-r--r--   3 hbase hbase         37 2019-06-01 15:59 /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd/.regioninfo      # region 描述目录
drwxr-xr-x   - hbase hbase          0 2019-06-08 21:06 /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd/.tmp             # 存储临时文件，比如某个合并产生的重新写回的文件
drwxr-xr-x   - hbase hbase          0 2019-06-08 21:06 /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd/picinfo          # 列族
drwxr-xr-x   - hbase hbase          0 2019-06-01 16:52 /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd/recovered.edits  # WAL 日志回放目录
[root@massive-dataset-new-005 ~]# hadoop fs -ls /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd/.regioninfo
-rw-r--r--   3 hbase hbase         37 2019-06-01 15:59 /hbase/data/default/tu/44b1f7dc0ce95cfd867d69a17f26b1fd/.regioninfo      # region 描述文件
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;在-zk-目录结构&quot;&gt;在 zk 目录结构&lt;/h4&gt;

&lt;p&gt;查看 Zookeeper 内部 HBase 相关数据，有三个主要的渠道:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;通过 hbase shell 命令 zk_dump 查看&lt;/li&gt;
  &lt;li&gt;通过 hbase zkcli 查看&lt;/li&gt;
  &lt;li&gt;通过 Zookeeper 查看&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 0] ls /hbase
[meta-region-server, acl, backup-masters, table, draining, region-in-transition, running, table-lock, master, balancer, namespace, hbaseid, online-snapshot, replication, splitWAL, recovering-regions, rs, flush-table-proc]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hbase(main):001:0&amp;gt; zk_dump
HBase is rooted at /hbase
Active master address: datanode1,60000,1483706056881
Backup master addresses:
Region server holding hbase:meta: datanode3,60020,1483706055770
Region servers:
 datanode2,60020,1483706054731
 datanode0,60020,1483706054027
 datanode4,60020,1483706055881
 datanode3,60020,1483706055770
 datanode7,60020,1483706055693
 datanode5,60020,1483706054452
/hbase/replication: 
/hbase/replication/peers: 
/hbase/replication/rs: 
/hbase/replication/rs/datanode5,60020,1483706054452: 
/hbase/replication/rs/datanode7,60020,1483706055693: 
/hbase/replication/rs/datanode3,60020,1483706055770: 
/hbase/replication/rs/datanode4,60020,1483706055881: 
/hbase/replication/rs/datanode0,60020,1483706054027: 
/hbase/replication/rs/datanode2,60020,1483706054731: 
Quorum Server Statistics:
 localhost:2181
  Zookeeper version: 3.4.5-cdh5.7.2--1, built on 07/22/2016 19:18 GMT
  Clients:
   /172.16.171.9:48487[1](queued=0,recved=5107,sent=5107)
   /172.16.171.17:36252[1](queued=0,recved=50936,sent=50936)
   /172.16.171.20:47011[1](queued=0,recved=19631,sent=19631)
   /172.16.171.19:62253[1](queued=0,recved=7455,sent=7455)
   /127.0.0.1:18625[1](queued=0,recved=22,sent=22)
   /172.16.171.11:34643[1](queued=0,recved=7456,sent=7456)
   /127.0.0.1:18621[1](queued=0,recved=3,sent=3)
   /172.16.171.21:38192[1](queued=0,recved=7467,sent=7467)
   /172.16.171.17:36254[1](queued=0,recved=50936,sent=50936)
   /172.16.171.5:60302[1](queued=0,recved=7456,sent=7456)
   /172.16.171.9:48540[1](queued=0,recved=25518,sent=25518)
   /172.16.171.9:32467[1](queued=0,recved=7455,sent=7455)
   /172.16.171.8:61522[1](queued=0,recved=10566,sent=10586)
   /172.16.171.19:16777[1](queued=0,recved=25518,sent=25518)
   /127.0.0.1:18626[0](queued=0,recved=1,sent=0)
   /172.16.171.8:45515[1](queued=0,recved=7455,sent=7455)
   /172.16.171.12:18371[1](queued=0,recved=381742,sent=381742)
  
  Latency min/avg/max: 0/3/51663
  Received: 1431771
  Sent: 1461307
  Connections: 17
  Outstanding: 0
  Zxid: 0x2600046a80
  Mode: follower
  Node count: 5349
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关于输出结果的解读，就不去细说了，感兴趣的兄弟，自己去问度娘吧。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/4e4f5f558816&quot;&gt;hbase数据存储&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/L_15156024189/article/details/83444255&quot;&gt;hbase在hdfs上的详细目录结构&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/hadoopdev/p/3984318.html&quot;&gt;HBase与Zookeeper数据结构查询&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.bcmeng.com/post/hbase-hdfs.html&quot;&gt;HBase 在HDFS上的物理目录结构&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">HBase 在 HDFS 存储目录结构、在 Zookeeper 的目录结构</summary></entry><entry><title type="html">HBase Data Block Encoding Types 介绍(转)</title><link href="http://localhost:4000/2019/06/19/HBase-Data-Block-Encoding-Types/" rel="alternate" type="text/html" title="HBase Data Block Encoding Types 介绍(转)" /><published>2019-06-19T00:00:00+00:00</published><updated>2019-06-19T00:00:00+00:00</updated><id>http://localhost:4000/2019/06/19/HBase-Data-Block-Encoding-Types</id><content type="html" xml:base="http://localhost:4000/2019/06/19/HBase-Data-Block-Encoding-Types/">&lt;p&gt;本文大部分内容都是转载于 AlstonWilliams 的&lt;a href=&quot;https://www.jianshu.com/p/a62e49f749f3&quot;&gt;HBase Data Block Encoding Types介绍&lt;/a&gt;，其中穿插些自己理解和认为的内容。&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;为什么需要 Data Block Encoding Types&lt;/p&gt;

&lt;p&gt;这里简单介绍一下HFile的组成，让读者知道什么是 Data Block Encoding．&lt;/p&gt;

&lt;p&gt;HFile 中，包含了好几个部分，具体的请查看&lt;a href=&quot;https://blog.cloudera.com/blog/2012/06/hbase-io-hfile-input-output/&quot;&gt;HFile Format&lt;/a&gt;．&lt;/p&gt;

&lt;p&gt;这里只关心 HFile 里的 Data Block．&lt;/p&gt;

&lt;p&gt;HFile 在存储每一个 Row 时，不是把这一条 Row 的全部 Family/Column 整合成在一起，保存起来的，如下:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;RowKey | Family:Column1 -&amp;gt; value | Family:Column2 -&amp;gt; value
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;它是把这条 Row，根据 Column 拆分成好几个 KeyValue，保存起来的，如下:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;RowKey/Family:Column1 -&amp;gt; value
RowKey/Family:Column2 -&amp;gt; value
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们可以看到，RowKey 需要重复保存很多次，而且 Family:Column 这个往往都是非常相似的，它也需要保存很多次．这对磁盘非常不友好．
当 Family:Column 越多时，就需要占用越多不必要的磁盘空间．&lt;/p&gt;

&lt;p&gt;如果仅仅是磁盘空间，也没什么关系，毕竟我们可以通过 Snappy/GZ 等压缩方式，对 HFile 进行 Compression．而且磁盘又便宜，对吧？&lt;/p&gt;

&lt;p&gt;可是，对 HBase 熟悉的读者，都知道，当读取数据时，读取的数据会缓存在 BlockCache 中的．那我们的 Block 越小，能放到 BlockCache 中的数据就越多，命中率就越高，对 Scan 就越友好．&lt;/p&gt;

&lt;p&gt;Block Encoding 就是做这件事情的，它就是通过某种算法，对 Data Block 中的数据进行压缩，这样 Block 的 Size 小了，放到 BlockCache 中的就多了．&lt;/p&gt;

&lt;p&gt;这儿提出两个问题:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;压缩以后，占的 Disk/Memory 是少了，但是解压的时候，需要更多的CPU时间．如何均衡呢?&lt;/li&gt;
  &lt;li&gt;如果我们的业务，偏重的是随机 Get，那放到 Block Cache 中不一定好吧？不仅放到 Block Cache 中的 Block 很容易读不到，对性能并没有什么提升，还会产生额外的开销，
比如将其它偏重 Scan 的业务的Block排挤出 Block Cache，导致其它业务变慢．&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;块压缩&quot;&gt;块压缩&lt;/h4&gt;

&lt;p&gt;HBase 中提供了五种 Data Block Encoding Types，具体有:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;NONE&lt;/li&gt;
  &lt;li&gt;PREFIX&lt;/li&gt;
  &lt;li&gt;DIFF&lt;/li&gt;
  &lt;li&gt;FAST_DIFF&lt;/li&gt;
  &lt;li&gt;PREFIX_TREE&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NONE&lt;/code&gt;这种就不介绍了，这个很容易理解。&lt;/p&gt;

&lt;h5 id=&quot;prefix&quot;&gt;PREFIX&lt;/h5&gt;

&lt;p&gt;一般来说，同一个Block中的Key(KeyValue中的Key，不仅包含RowKey，还包含Family:Column)，
都很相似．它们往往只是最后的几个字符不同．
例如，KeyA是&lt;code class=&quot;highlighter-rouge&quot;&gt;RowKey:Family:Qualifier0&lt;/code&gt;，
跟它相邻的下一个KeyB可能是&lt;code class=&quot;highlighter-rouge&quot;&gt;RowKey:Family:Qualifier1&lt;/code&gt;．&lt;/p&gt;

&lt;p&gt;在PREFIX中，相对于NONE，会额外添加一列，表示当前key(KeyB)和它前一个key(KeyA)，
相同的前缀的长度(记为PrefixLength)．在上面的例子中，如果KeyA是这个Block中的第一个key，
那它的PrefixLength就是0．而KeyB的PrefixLength是23．&lt;/p&gt;

&lt;p&gt;很明显，如果相邻 Key 之间，完全没有共同点，那 PREFIX 显然毫无用处，还增加了额外的开销．&lt;/p&gt;

&lt;p&gt;下面一些 Row，当使用 NONE 这种 Block Encoding时，如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-19-1.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而如果采用 PREFIX 这种数据块编码，如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-19-2.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;diff&quot;&gt;DIFF&lt;/h5&gt;

&lt;p&gt;DIFF 是对 PREFIX 的一种改良．不在把 Key 看成单个字节序列，而是分割每个字段，对每字段进行压缩，提高效率。&lt;/p&gt;

&lt;p&gt;它添加了两个新的字段，&lt;code class=&quot;highlighter-rouge&quot;&gt;timestamp&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt;．&lt;/p&gt;

&lt;p&gt;如果 KeyB 的 ColumnFamily、key length、value length、Key type 和 KeyA 对应字段相同，那么它就会在 KeyB 中被省略．&lt;/p&gt;

&lt;p&gt;此外，timestamp 存储的是相对于前一行 Row 的 timestamp 偏移量，而不是完整存储。&lt;/p&gt;

&lt;p&gt;默认情况下，DIFF 是不启用的．因为它会导致写数据，以及 Scan 数据更慢．但是，相对于 PREFIX/NONE，它会在 BlockCache 中缓存更多数据．&lt;/p&gt;

&lt;p&gt;用 DIFF 编码方式压缩之前的 block 如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2019-06-19-3.png&quot; alt=&quot;&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;示例中的第一第二两个行键，并给出时间戳和相同类型的精确匹配，第二行的 value length 或 type 都不需要存储，第二行的时 timestamp 只有0，而不是一个完整的 timestamp。&lt;/p&gt;

&lt;h5 id=&quot;fast_diff&quot;&gt;FAST_DIFF&lt;/h5&gt;

&lt;p&gt;FAST_DIFF跟DIFF非常相似，所不同的是，它额外增加了一个字段，表示 RowB 是否跟 RowA 完全一样，如果是的话，那数据就不需要重复保存了．&lt;/p&gt;

&lt;p&gt;如果在你的场景下，Key很长，或者有很多Column，那么推荐使用FAST_DIFF．&lt;/p&gt;

&lt;p&gt;数据格式几乎与 DIFF 编码相同，因此没有图像来说明它。&lt;/p&gt;

&lt;h5 id=&quot;prefix_tree&quot;&gt;PREFIX_TREE&lt;/h5&gt;

&lt;p&gt;PREFIX_TREE 是0.96 中引入的．它大致跟 PREFIX,DIFF,FAST_DIFF 相同，但是它可以让随机读操作，比其它的几种更快．&lt;br /&gt;
当然，代价是，memStore 写入到 HFile 时，需要进行更加复杂的 Encoding 操作，所以会更慢。
(AlstonWilliams译者疑问:那Decoding的时候也会更慢啊，而且随机读的话，Block很可能不存在于Block Cache中，那开销主要都在Decoding的时候，所以随机读操作不应该是更慢么?)．&lt;/p&gt;

&lt;p&gt;PREFIX_TREE 适合于那种 Block Cache 命中率非常高的场景(AlstonWilliams译者注:-.-!)．它增加了一个叫做tree的字段．这个字段会保存指向这一Row中，
全部Cell的索引．这对压缩更加友好。&lt;/p&gt;

&lt;p&gt;详情请查看 &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4676&quot;&gt;HBASE-4676&lt;/a&gt; 以及 &lt;a href=&quot;http://en.wikipedia.org/wiki/Trie&quot;&gt;Trie&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PREFIX_TREE 可能存在些问题。它已在 HBase-2.0.0 中删除。&lt;/p&gt;

&lt;p&gt;本人在学习过程中有搜到因使用 PREFIX_TREE 这种 Block Encoding 发生的故障案例:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/Cbtq5LSN_NmKKvv_a4oyHw&quot;&gt;HBase表Major&amp;amp;Minor Compaction无法结束问题排查&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/a3a81a9d472c&quot;&gt;HBase PrefixTree以及64KB的BLOCKSIZE导致Get阻塞的问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何选择-block-encoding-type&quot;&gt;如何选择 Block Encoding Type?&lt;/h4&gt;

&lt;p&gt;要使用的压缩或编解码器类型取决于数据的特征。选择错误的类型可能会导致数据占用更多空间而不是更少，并且可能会影响性能。&lt;/p&gt;

&lt;p&gt;通常，您需要在较小尺寸和较快压缩/解压缩之间权衡您的选择。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果 Key 很长(与 Value 相比)，或者有很多Column，那么推荐使用 FAST_DIFF&lt;/li&gt;
  &lt;li&gt;如果数据是冷数据，不经常被访问，那么使用 GZIP 压缩格式．因为虽然它比 Snappy/LZO 需要占用更多而 CPU，但是它的压缩比率更高，更节省磁盘．&lt;/li&gt;
  &lt;li&gt;如果是热点数据，那么使用Snappy/LZO压缩格式．它们相比GZIP，占用的CPU更少．&lt;/li&gt;
  &lt;li&gt;在大多数情况下，Snappy/LZO的选择都更好.&lt;/li&gt;
  &lt;li&gt;Snappy比LZO更好&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里都是针对 Key 的压缩。如果 Value 很大（而不是预压缩，例如图像），请使用 Block Compressors。&lt;/p&gt;

&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;

&lt;p&gt;本文主要翻译自&lt;a href=&quot;http://hbase.apache.org/book.html#compression&quot;&gt;HBase官方文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;因公司使用的是 1.2.x HBase 版本所以有需求可以阅读下1.2.x 版本的&lt;a href=&quot;http://hbase.apache.org/1.2/book.html#compression&quot;&gt;HBase官方文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里推荐三篇关于不同Block Encoding Type以及压缩算法对磁盘以及性能有什么影响的文章．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://hadoop-hbase.blogspot.com/2016/02/hbase-compression-vs-blockencoding_17.html&quot;&gt;HBase - Compression vs Block Encoding&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/hbase/entry/the_effect_of_columnfamily_rowkey&quot;&gt;The Effect of ColumnFamily, RowKey and KeyValue Design on HFile Size&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://hbasefly.com/2016/07/02/hbase-pracise-cfsetting/&quot;&gt;HBase最佳实践－列族设计优化&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;参考链接&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/a62e49f749f3&quot;&gt;HBase Data Block Encoding Types介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>lihuimintu</name></author><summary type="html">本文大部分内容都是转载于 AlstonWilliams 的HBase Data Block Encoding Types介绍，其中穿插些自己理解和认为的内容。</summary></entry></feed>